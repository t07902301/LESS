{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLE VAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_relative_path = '../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# load sgd gradients of ref points\n",
    "ref_grads = torch.load(grad_relative_path + 'grads/TinyLlama/TinyLlama-1.1B-Chat-v1.0-p0.1-lora-seed3/mmlu-ckpt92-sgd/dim8192/all_orig.pt')\n",
    "if not torch.is_tensor(ref_grads):\n",
    "    ref_grads = torch.tensor(ref_grads)\n",
    "ref_grads = ref_grads.to(device).float()\n",
    "# load adam gradients of val points\n",
    "val_grads = torch.load(grad_relative_path + 'grads/TinyLlama/TinyLlama-1.1B-Chat-v1.0-p0.1-lora-seed3/fake_val/dolly-ckpt92-adam/dim8192/all_orig.pt')\n",
    "if not torch.is_tensor(val_grads):\n",
    "    val_grads = torch.tensor(val_grads)\n",
    "val_grads = val_grads.to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7506, 8192])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1501, 8192])\n"
     ]
    }
   ],
   "source": [
    "def sample_tensor(tensor, sample_fraction=0.2, seed=0): \n",
    "    torch.manual_seed(seed)\n",
    "    num_samples = int(tensor.size(0) * sample_fraction)\n",
    "    indices = torch.randperm(tensor.size(0))[:num_samples]\n",
    "    return tensor[indices], indices\n",
    "\n",
    "sampled_val_grads, sampled_indices = sample_tensor(val_grads, 0.2, seed=0) # sampled_indices is the indices of samples from the original file\n",
    "print(sampled_val_grads.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(training_info: torch.Tensor, validation_info: torch.Tensor):\n",
    "    \"\"\"Calculate the cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        training_info (torch.Tensor): training info (gradients/representations) stored in a tensor of shape N x N_DIM\n",
    "        validation_info (torch.Tensor): validation info (gradients/representations) stored in a tensor of shape N_VALID x N_DIM\n",
    "    \"\"\"\n",
    "    # N x N_VALID\n",
    "    cosine_similarity = torch.matmul(\n",
    "        training_info, validation_info.transpose(0, 1))\n",
    "    # cosine_similarity = cosine_similarity / (training_info.norm(dim=1)[:, None] * validation_info.norm(dim=1))\n",
    "    # cosine_distance = 1 - cosine_similarity\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1501, 285])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_cos = calculate_cosine_similarity(sampled_val_grads, ref_grads)\n",
    "grads_cos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1501])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cos = grads_cos.mean(-1)\n",
    "mean_cos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mean_cos, _ = torch.sort(mean_cos)\n",
    "# print(sorted_mean_cos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7546e-07, device='cuda:0') tensor(0.0056, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_samples = sorted_mean_cos.size(0)\n",
    "chunk_size = n_samples // 3\n",
    "low_threshold = sorted_mean_cos[chunk_size]\n",
    "high_threshold = sorted_mean_cos[2 * chunk_size]\n",
    "print(low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1501])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.empty_like(mean_cos, dtype=torch.long)\n",
    "\n",
    "labels[mean_cos < low_threshold] = 0\n",
    "labels[(mean_cos >= low_threshold) & (mean_cos < high_threshold)] = 1\n",
    "labels[mean_cos >= high_threshold] = 2\n",
    "\n",
    "# print(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2, 2, 1], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save (Text, Grad, Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from typing import Union, List\n",
    "\n",
    "def load_raw_dataset(train_files: Union[List[str], str]):\n",
    "    \"\"\" load raw dataset \"\"\"\n",
    "    if isinstance(train_files, str):\n",
    "        train_files = [train_files]\n",
    "    processed_datasets = load_dataset(\n",
    "        \"json\",\n",
    "        data_files=train_files,\n",
    "    )[\"train\"]\n",
    "    return processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = '../data/train/processed/dolly/val_dolly_data.jsonl'\n",
    "texts = load_raw_dataset(text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def sample_dataset(dataset: Dataset, indices: torch.Tensor) -> Dataset:\n",
    "    \"\"\"Sample from a dataset based on indices tensor.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): The dataset to sample from.\n",
    "        indices (torch.Tensor): The indices tensor.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: The sampled dataset.\n",
    "    \"\"\"\n",
    "    sampled_dataset = dataset.select(indices.tolist())\n",
    "    return sampled_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/filter/dolly/all.jsonl', 'w', encoding='utf-8') as file:\n",
    "    for text, cos, label in zip(texts, mean_cos, labels):\n",
    "        data = {\n",
    "            \"text\": text,\n",
    "            \"cos\": cos.item(),\n",
    "            \"label\": label.item()\n",
    "        }\n",
    "        file.write(json.dumps(data, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'dolly',\n",
       " 'id': 'dolly_7505',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': \"What was Canon EOS DCS 1 resolution?\\nInput: The Canon EOS DCS 1 was Kodak's third Canon-based Digital SLR camera (a rebranded Kodak EOS DCS-1). It was released in December 1995, following the cheaper EOS DCS 3, which was released earlier that year. Like that camera, it combined an EOS-1N body with a modified Kodak DCS 460 digital back. Despite offering a then-enormous resolution of 6 megapixels with a relatively large APS-H sensor, a number of technical issues (together with its 3.6 million yen price) meant that it was never a very popular camera other than for a few people with specialized roles.\\n\\nAlthough the sensor was much larger than the EOS DCS 3, the DCS 1 had a lower fixed sensitivity of ISO 80. The large image size resulted in a burst rate of just over one image per second for two images, followed by an eight-second delay to clear the buffer. A typical contemporary 340MB PCMCIA card or IBM Microdrive could store 53 images. In line with the rest of the Kodak DCS range, the EOS DCS 1 could not produce JPEG files in camera.\\n\\nThe EOS DCS 1 was succeeded in 1998 by the EOS D6000 (a rebranded Kodak DCS 560).\\nOutput:\"},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'The Canon EOS DCS 1 had a resolution of 6 megapixels, which at that time of release was considered to be a breakthrough in technology.'}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0063, device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
